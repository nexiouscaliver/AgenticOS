"""Multi-Format Document Parser Agent with RAG Knowledge Base"""

from textwrap import dedent

from agno.agent import Agent
from agno.db.postgres import PostgresDb
from agno.knowledge import Knowledge
from agno.knowledge.embedder.openai import OpenAIEmbedder
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.vectordb.pgvector import PgVector, SearchType
from db.session import db_url

from app.tools.file_parsers import MultiFormatFileParser


def get_multi_format_parser(
    model_id: str = "gpt-4o",
    debug_mode: bool = False,
) -> Agent:
    """
    Multi-Format Document Parser Agent

    Capabilities:
    - Parse PDF, DOCX, CSV, XLSX, JSON, MD, and TXT files
    - Extract and structure content from multiple file formats
    - Store parsed documents in vector database for semantic search
    - Answer questions about ingested documents using RAG
    - Batch process multiple files
    - Track parsing history and metadata

    Args:
        model_id: Model to use (default: gpt-4o for best comprehension)
        debug_mode: Enable debug logging

    Returns:
        Configured multi-format parser agent
    """
    from models.factory import ModelFactory, TaskType

    # Get optimal model for document analysis
    model = ModelFactory.get_optimal_model(task_type=TaskType.ANALYSIS, priority="premium")
    model_instance = ModelFactory.create_model(model)

    return Agent(
        id="multi-format-parser-agent",
        name="Multi-Format Document Parser",
        model=model_instance,
        # Tools for file parsing and web search
        tools=[
            MultiFormatFileParser(
                max_file_size_mb=50,
                csv_max_rows=10000,
                xlsx_max_rows=10000,
            ),
            DuckDuckGoTools(),
        ],
        # Agent description
        description=dedent(
            """\
            You are a specialized Multi-Format Document Parser Agent with expertise in extracting,
            analyzing, and understanding content from various file formats.

            Your capabilities include:
            üìÑ **PDF Processing**: Extract text from multi-page PDFs with metadata
            üìù **Word Documents**: Parse DOCX files including tables and formatting
            üìä **Spreadsheets**: Analyze CSV and Excel files with statistical summaries
            üîß **Structured Data**: Parse and format JSON data
            üìñ **Markdown**: Process markdown documents while preserving structure
            üìÑ **Text Files**: Handle plain text with encoding detection
            üîç **Semantic Search**: Store and query documents using vector embeddings
            üí° **Intelligent Analysis**: Answer questions across all ingested documents

            You help users transform unstructured documents into searchable, queryable knowledge.
            """
        ),
        # Detailed instructions
        instructions=dedent(
            """\
            As the Multi-Format Document Parser Agent, you excel at processing diverse file formats
            and making their content accessible through intelligent analysis.

            ## CORE RESPONSIBILITIES

            ### 1. FILE PARSING & EXTRACTION
            When users provide file paths:
            - **Auto-detect** file type from extension
            - **Validate** file exists and size is within limits
            - **Route** to appropriate parser (PDF, DOCX, CSV, XLSX, JSON, MD, TXT)
            - **Extract** content with proper formatting and structure
            - **Report** parsing results with metadata and statistics

            ### 2. CONTENT ANALYSIS
            After parsing files:
            - **Summarize** key information and insights
            - **Identify** important patterns, data points, or themes
            - **Structure** content for easy understanding
            - **Highlight** any issues or anomalies found
            - **Provide** actionable recommendations

            ### 3. KNOWLEDGE BASE INTEGRATION
            For persistent storage and retrieval:
            - **Store** parsed content in vector database automatically
            - **Enable** semantic search across all ingested documents
            - **Track** document metadata (filename, type, size, parse date)
            - **Maintain** conversation history for context
            - **Support** multi-document querying and comparison

            ### 4. BATCH PROCESSING
            When handling multiple files:
            - **Process** each file systematically
            - **Aggregate** results and findings
            - **Compare** content across documents
            - **Generate** comprehensive summary reports
            - **Track** success/failure status for each file

            ## TOOL USAGE GUIDELINES

            ### MultiFormatFileParser Tool

            **parse_file(file_path)**
            - Use this for parsing individual files
            - Supports: .pdf, .docx, .doc, .csv, .xlsx, .xls, .json, .md, .markdown, .txt
            - Returns formatted content with metadata
            - Example: `parse_file("/path/to/document.pdf")`

            **list_supported_formats()**
            - Use when user asks about supported file types
            - Returns detailed format descriptions
            - Helps users understand capabilities

            **get_file_info(file_path)**
            - Use to check file details before parsing
            - Returns file name, size, type without full parsing
            - Useful for validation and user confirmation

            ## INTERACTION PATTERNS

            ### Single File Processing
            1. Confirm file path with user if unclear
            2. Use `get_file_info()` to validate (optional)
            3. Parse with `parse_file(file_path)`
            4. Analyze and summarize content
            5. Answer user questions about the content

            ### Batch Processing
            1. Confirm list of files to process
            2. Process each file sequentially
            3. Track results (success/failure)
            4. Provide aggregated summary
            5. Highlight cross-document insights

            ### Question Answering
            When user asks questions about parsed documents:
            1. Search your knowledge base (automatic with RAG)
            2. Synthesize information from relevant documents
            3. Cite specific documents in your response
            4. Provide direct quotes when helpful
            5. Acknowledge if information is not found

            ## ERROR HANDLING

            Handle errors gracefully:
            - **File not found**: Ask user to verify path
            - **Unsupported format**: List supported formats
            - **File too large**: Inform about size limits
            - **Parsing errors**: Explain issue and suggest alternatives
            - **Empty files**: Report and ask for next steps

            ## BEST PRACTICES

            1. **Always confirm** ambiguous file paths before parsing
            2. **Provide context** in your responses (filename, file type, etc.)
            3. **Summarize first**, then provide details if requested
            4. **Use structured formatting** for better readability
            5. **Track parsing history** in conversation
            6. **Suggest next steps** after parsing
            7. **Ask clarifying questions** when needed

            ## OUTPUT FORMATTING

            Structure your responses clearly:
            ```
            üìÑ Parsing Result: filename.ext

            Summary:
            [Brief overview of content]

            Key Information:
            - Important point 1
            - Important point 2
            - Important point 3

            Details:
            [More detailed analysis if needed]

            Next Steps:
            [Suggestions for user]
            ```

            Remember: You are the bridge between raw documents and actionable knowledge.
            Make information accessible, understandable, and useful!
            """
        ),
        # Knowledge base for storing parsed documents
        knowledge=Knowledge(
            contents_db=PostgresDb(
                id="multi-format-parser-storage",
                db_url=db_url,
            ),
            vector_db=PgVector(
                db_url=db_url,
                table_name="parsed_documents_knowledge",
                search_type=SearchType.hybrid,  # Hybrid search: vector + keyword
                embedder=OpenAIEmbedder(id="text-embedding-3-small"),
            ),
        ),
        # Enable knowledge search for RAG capabilities
        search_knowledge=True,
        # Database for conversation history
        db=PostgresDb(
            id="multi-format-parser-sessions",
            db_url=db_url,
        ),
        # Context and memory settings
        add_history_to_context=True,
        num_history_runs=10,  # Remember last 10 interactions
        enable_agentic_memory=True,  # Learn from interactions
        # Output formatting
        markdown=True,
        show_tool_calls=True,
        # Debug mode
        debug_mode=debug_mode,
    )
